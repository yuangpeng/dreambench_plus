import glob
import itertools
import json
import os
import random
import re
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Literal

import fire

from dreambench_plus.constants import DREAMBENCH_PLUS_DIR, METHODS
from dreambench_plus.dreambench_plus_dataset import DreamBenchPlus
from dreambench_plus.utils.gpt_utils import call_gpt, encode_image_into_base64
from dreambench_plus.utils.image_utils import load_image
from dreambench_plus.utils.loguru import logger
from dreambench_plus.utils.misc import listdir, truly_random_seed


def execute_gpt_task(
    method,
    method_dir,
    collection_id,
    prompt_index,
    category,
    ablation_settings,
    few_shot,
    out_dir,
    model_name,
    max_retry,
):
    # Get instruction and source image
    instruction_path = f"{method_dir}/text/{collection_id}/{prompt_index}_0.txt"
    with open(instruction_path, "r") as file:
        instruction = file.readline().strip()
    src_image = load_image(f"{method_dir}/src_image/{collection_id}/{prompt_index}_0.jpg").resize((512, 512))
    src_image = encode_image_into_base64(src_image)

    # Get images generated by method
    tgt_image = load_image(f"{method_dir}/tgt_image/{collection_id}/{prompt_index}_0.jpg").resize((512, 512))
    tgt_image = encode_image_into_base64(tgt_image)

    current_file_path = Path(__file__).resolve()
    current_dir = current_file_path.parent

    if ablation_settings == "wo_internal_thinking":
        with open(os.path.join(current_dir, f"prompts/user_prompt_{category}_full.txt"), "r") as f:
            user_prompt = f.read().strip()
    else:
        with open(os.path.join(current_dir, f"prompts/user_prompt_{category}_{ablation_settings}.txt"), "r") as f:
            user_prompt = f.read().strip()
        with open(os.path.join(current_dir, f"prompts/gpt_prompt_{category}_{ablation_settings}.txt"), "r") as f:
            gpt_prompt = f.read().strip()

    cur_retry = 0
    try:
        while True:
            try:
                # fmt: off
                if ablation_settings == "wo_internal_thinking":
                    messages = [
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": user_prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{src_image}", "detail": "high"}},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{tgt_image}", "detail": "high"}},
                            ],
                        },
                    ]
                else:
                    messages = [
                        {"role": "user", "content": user_prompt},
                        {"role": "assistant", "content": gpt_prompt},
                        {
                            "role": "user",
                            "content": [
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{src_image}", "detail": "high"}},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{tgt_image}", "detail": "high"}},
                            ],
                        },
                    ]
                # fmt: on
                if few_shot > 0:

                    def _get_k_shot(_k):
                        shot = []
                        files = glob.glob("few_shot/*.json")
                        for _ in range(_k):
                            rng = random.Random(truly_random_seed())
                            file = rng.choice(files)
                            with open(file, "r") as f:
                                data = json.load(f)
                            shot.append(rng.choice(data))
                        return shot

                    def construct_messages_for_one_shot(_shot, _ablation_settings):
                        _method_dir = METHODS[_shot["method"]]

                        # fmt: off
                        shot_src_image = load_image(f"{_method_dir}/src_image/{_shot['collection_id']}/{_shot['prompt_index']}_0.jpg").resize((512, 512))
                        shot_src_image = encode_image_into_base64(shot_src_image)

                        shot_tgt_image = load_image(f"{_method_dir}/tgt_image/{_shot['collection_id']}/{_shot['prompt_index']}_0.jpg").resize((512, 512))
                        shot_tgt_image = encode_image_into_base64(shot_tgt_image)
                        # fmt: on

                        if _ablation_settings == "w_cot":
                            gpt_response = _shot["content"]
                        else:
                            _pattern = r"(score|Score):\s*[a-zA-Z]*\s*(\d+)"
                            _score = re.findall(_pattern, _shot["content"])
                            _score = [int(s) for _, s in _score]
                            assert len(_score) == 1
                            _score = _score[0]

                            gpt_response = f"Score: {_score}"

                        # fmt: off
                        _messages = [
                            {
                                "role": "user",
                                "content": [
                                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{shot_src_image}", "detail": "high"}},
                                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{shot_tgt_image}", "detail": "high"}},
                                ],
                            },
                            {"role": "assistant", "content": gpt_response}
                        ]
                        # fmt: on

                        return _messages

                    shot = _get_k_shot(few_shot)

                    few_shot_msg = []
                    for _shot in shot:
                        few_shot_msg.extend(construct_messages_for_one_shot(_shot, ablation_settings))

                    messages = messages[:-1] + few_shot_msg + messages[-1:]

                content = call_gpt(messages, model=model_name, temperature=1, seed=truly_random_seed())
                pattern = r"(score|Score):\s*[a-zA-Z]*\s*(\d+)"

                score = re.findall(pattern, content)
                score = [int(s) for _, s in score]
                assert len(score) == 1
                score = score[0]
                break

            except:
                cur_retry += 1
                time.sleep(0.1)

            if cur_retry >= max_retry:
                logger.warning("Reached maximum retry limit.")
                break

    except KeyboardInterrupt:
        logger.error("Program interrupted by user. Exiting...")

    if cur_retry < max_retry:
        result = {
            "method": method,
            "collection_id": collection_id,
            "prompt_index": prompt_index,
            "score": score,
            "content": content,
        }
        logger.info(result)
        with open(os.path.join(out_dir, f"{method}-{collection_id}-{prompt_index}.json"), "w") as f:
            json.dump(result, f, indent=4)
        return True
    else:
        logger.error(f"Failed to evaluate {method}-{collection_id}-{prompt_index}.")
        return False


def main(
    data_dir: str = DREAMBENCH_PLUS_DIR,
    method: str = "DreamBooth LoRA SDXL",
    out_dir: str = "data_gpt_rating/concept_preservation_full/dreambooth_lora_sdxl",
    category: Literal["subject", "style"] = "subject",
    ablation_settings: Literal[
        "full",
        "wo_internal_thinking",
        "w_human_prior",
        "w_cot",
        "wo_scoring_range",
        "wo_scoring_criteria",
    ] = "full",
    few_shot: int = 0,
    model_name: str = "gpt-4o-2024-05-13",
    resume: bool = True,
    num_workers: int = 32,
    max_retry: int = 3,
):
    if ablation_settings.startswith("full"):
        ablation_settings = "full"
    os.makedirs(out_dir, exist_ok=True)
    dataset = DreamBenchPlus(data_dir)

    if category == "subject":
        collection_ids = [collection.collection_id for collection in dataset if collection.category != "style"]
    elif category == "style":
        collection_ids = [collection.collection_id for collection in dataset if collection.category == "style"]
    else:
        raise ValueError(f"Invalid category: {category}")
    prompt_num = len(dataset[0].captions)
    assert prompt_num == 9, "Prompt number should be 9"

    combinations = set(itertools.product(collection_ids, range(prompt_num)))
    if resume:
        done_files = listdir(out_dir)
        done_files = [f.split(".")[0] for f in done_files]
        for f in done_files:
            assert (
                f.split("-")[0] == method.replace(" ", "_").replace("-", "_").lower()
            ), f"Method {f.split('-')[0]} is not consistent with the current method {method}."
        done_files = [
            (
                (f.split("-")[1], int(f.split("-")[-1]))
                if "cotton-top_tamarin" not in f
                and "spider-man" not in f
                and "t-shirt" not in f
                and "tree-like_character" not in f
                and "rolls-royce_hood_ornament" not in f
                and "low-poly_geometric" not in f
                and "ukiyo-e" not in f
                else ("-".join([f.split("-")[1], f.split("-")[2]]), int(f.split("-")[-1]))
            )
            for f in done_files
        ]
        done_files = set(done_files)
        logger.info(f"{len(done_files)} files are evaluated, continue from there.")
        combinations = combinations - done_files

        if len(combinations) == 0:
            logger.info("All files are evaluated.")
            return

    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = [
            executor.submit(
                execute_gpt_task,
                method,
                METHODS[method],
                collection_id,
                prompt_index,
                category,
                ablation_settings,
                few_shot,
                out_dir,
                model_name,
                max_retry,
            )
            for collection_id, prompt_index in combinations
        ]


if __name__ == "__main__":
    fire.Fire(main)
