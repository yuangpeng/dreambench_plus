import itertools
import json
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Literal

import fire

from dreambench_plus.constants import DREAMBENCH_PLUS_DIR, METHODS
from dreambench_plus.dreambench_plus_dataset import DreamBenchPlus
from dreambench_plus.utils.gpt_utils import call_gpt, encode_image_into_base64
from dreambench_plus.utils.image_utils import load_image
from dreambench_plus.utils.loguru import logger
from dreambench_plus.utils.misc import listdir, truly_random_seed


def execute_gpt_task(
    method,
    method_dir,
    collection_id,
    prompt_index,
    ablation_settings,
    out_dir,
    model_name,
    max_retry,
):
    # Get instruction and source image
    instruction_path = f"{method_dir}/text/{collection_id}/{prompt_index}_0.txt"
    with open(instruction_path, "r") as file:
        instruction = file.readline().strip()

    # Get images generated by method
    tgt_image = load_image(f"{method_dir}/tgt_image/{collection_id}/{prompt_index}_0.jpg").resize((512, 512))
    tgt_image = encode_image_into_base64(tgt_image)

    current_file_path = Path(__file__).resolve()
    current_dir = current_file_path.parent

    if ablation_settings == "wo_gpt_prompt":
        with open(os.path.join(current_dir, f"prompts/user_prompt_text_full.txt"), "r") as f:
            user_prompt = f.read().strip()
    else:
        with open(os.path.join(current_dir, f"prompts/user_prompt_text_{ablation_settings}.txt"), "r") as f:
            user_prompt = f.read().strip()
        with open(os.path.join(current_dir, f"prompts/gpt_prompt_text_{ablation_settings}.txt"), "r") as f:
            gpt_prompt = f.read().strip()

    cur_retry = 0
    try:
        while True:
            try:
                # fmt: off
                if ablation_settings == "wo_gpt_prompt":
                    messages = [
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": user_prompt + f"\n\n### Text Prompt\n{instruction}"},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{tgt_image}", "detail": "high"}},
                            ],
                        },
                    ]
                else:
                    messages = [
                        {"role": "user", "content": user_prompt},
                        {"role": "assistant", "content": gpt_prompt},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": instruction},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{tgt_image}", "detail": "high"}},
                            ],
                        },
                    ]
                # fmt: on

                content = call_gpt(messages, model=model_name, temperature=1, seed=truly_random_seed())
                pattern = r"(score|Score):\s*[a-zA-Z]*\s*(\d+)"

                score = re.findall(pattern, content)
                score = [int(s) for _, s in score]
                assert len(score) == 1
                score = score[0]
                break

            except:
                cur_retry += 1
                time.sleep(0.1)

            if cur_retry >= max_retry:
                logger.warning("Reached maximum retry limit.")
                break

    except KeyboardInterrupt:
        logger.error("Program interrupted by user. Exiting...")

    if cur_retry < max_retry:
        result = {
            "method": method,
            "collection_id": collection_id,
            "prompt_index": prompt_index,
            "score": score,
            "content": content,
        }
        logger.info(result)
        with open(os.path.join(out_dir, f"{method}-{collection_id}-{prompt_index}.json"), "w") as f:
            json.dump(result, f, indent=4)
        return True
    else:
        logger.error(f"Failed to evaluate {method}-{collection_id}-{prompt_index}.")
        return False


def main(
    data_dir: str = DREAMBENCH_PLUS_DIR,
    method: str = "DreamBooth LoRA SDXL",
    out_dir: str = "data_gpt_rating/prompt_following_full/dreambooth_lora_sdxl",
    ablation_settings: Literal[
        "full",
        "wo_internal_thinking",
        "wo_cot",
        "wo_scoring_range",
        "wo_scoring_criteria",
    ] = "full",
    model_name: str = "gpt-4o-2024-05-13",
    resume: bool = True,
    num_workers: int = 32,
    max_retry: int = 3,
):
    if ablation_settings.startswith("full"):
        ablation_settings = "full"
    os.makedirs(out_dir, exist_ok=True)
    dataset = DreamBenchPlus(data_dir)

    collection_ids = [collection.collection_id for collection in dataset]
    prompt_num = len(dataset[0].captions)
    assert prompt_num == 9, "Prompt number should be 9"

    combinations = set(itertools.product(collection_ids, range(prompt_num)))
    if resume:
        done_files = listdir(out_dir)
        done_files = [f.split(".")[0] for f in done_files]
        for f in done_files:
            assert f.split("-")[0] == method, f"Method {f.split('-')[0]} is not consistent with the current method {method}."
        done_files = [
            (
                (f.split("-")[1], int(f.split("-")[-1]))
                if "cotton-top_tamarin" not in f
                and "spider-man" not in f
                and "t-shirt" not in f
                and "tree-like_character" not in f
                and "rolls-royce_hood_ornament" not in f
                and "low-poly_geometric" not in f
                and "ukiyo-e" not in f
                else ("-".join([f.split("-")[1], f.split("-")[2]]), int(f.split("-")[-1]))
            )
            for f in done_files
        ]
        done_files = set(done_files)
        logger.info(f"{len(done_files)} files are evaluated, continue from there.")
        combinations = combinations - done_files

        if len(combinations) == 0:
            logger.info("All files are evaluated.")
            return

    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = [
            executor.submit(
                execute_gpt_task,
                method,
                METHODS[method],
                collection_id,
                prompt_index,
                ablation_settings,
                out_dir,
                model_name,
                max_retry,
            )
            for collection_id, prompt_index in combinations
        ]


if __name__ == "__main__":
    fire.Fire(main)
